{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\21629\\appdata\\roaming\\python\\python312\\site-packages (1.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\21629\\appdata\\roaming\\python\\python312\\site-packages (2.31.0)\n",
      "Requirement already satisfied: tiktoken in c:\\python312\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\21629\\appdata\\roaming\\python\\python312\\site-packages (1.26.4)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in c:\\users\\21629\\appdata\\roaming\\python\\python312\\site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\python312\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\21629\\appdata\\roaming\\python\\python312\\site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\21629\\appdata\\roaming\\python\\python312\\site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\21629\\appdata\\roaming\\python\\python312\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in c:\\python312\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\21629\\appdata\\roaming\\python\\python312\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\21629\\appdata\\roaming\\python\\python312\\site-packages (from requests) (2023.11.17)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\python312\\lib\\site-packages (from tiktoken) (2024.7.24)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python312\\lib\\site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\21629\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\21629\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\21629\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\21629\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai requests tiktoken numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve key and endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "#load variable from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY_fine_tuning\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE_fine_tuning\")\n",
    "\n",
    "# Verify that it has been set\n",
    "print(openai.api_key)\n",
    "# Verify that it has been set\n",
    "print(openai.api_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in training set: 101\n",
      "First example in training set:\n",
      "{'role': 'system', 'content': 'You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.'}\n",
      "{'role': 'user', 'content': 'Title: No-Bake Nut Cookies\\n\\nIngredients: [\"1 c. firmly packed brown sugar\", \"1/2 c. evaporated milk\", \"1/2 tsp. vanilla\", \"1/2 c. broken nuts (pecans)\", \"2 Tbsp. butter or margarine\", \"3 1/2 c. bite size shredded rice biscuits\"]\\n\\nGeneric ingredients: '}\n",
      "{'role': 'assistant', 'content': '[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"butter\", \"bite size shredded rice biscuits\"]'}\n",
      "\n",
      "Number of examples in validation set: 100\n",
      "First example in validation set:\n",
      "{'role': 'system', 'content': 'You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.'}\n",
      "{'role': 'user', 'content': 'Title: Crustless Vegetable Ham Pie\\n\\nIngredients: [\"1/4 c. butter\", \"1/4 lb. mushrooms, sliced\", \"1 garlic clove, minced\", \"1 medium zucchini, sliced thinly\", \"1/4 c. chopped onion\", \"1 c. diced, cooked ham\", \"4 eggs\", \"2 c. Ricotta cheese\", \"1 c. shredded Monterey Jack\", \"1 (10 oz.) pkg. frozen spinach, thawed and drained\", \"1/2 tsp. dill weed\", \"salt and pepper\"]\\n\\nGeneric ingredients: '}\n",
      "{'role': 'assistant', 'content': '[\"butter\", \"mushrooms\", \"garlic\", \"zucchini\", \"onion\", \"eggs\", \"Ricotta cheese\", \"shredded Monterey Jack\", \"frozen spinach\", \"dill weed\", \"salt\"]'}\n"
     ]
    }
   ],
   "source": [
    "# Run preliminary checks\n",
    "\n",
    "import json\n",
    "\n",
    "# Load the training set\n",
    "with open(r'C:\\Users\\21629\\Desktop\\Danger!\\Projects\\GenAI\\data\\tmp_recipe_finetune_training.jsonl', 'r', encoding='utf-8') as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)\n",
    "\n",
    "# Load the validation set\n",
    "with open(r'C:\\Users\\21629\\Desktop\\Danger!\\Projects\\GenAI\\data\\tmp_recipe_finetune_validation.jsonl', 'r', encoding='utf-8') as f:\n",
    "    validation_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Validation dataset stats\n",
    "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
    "print(\"First example in validation set:\")\n",
    "for message in validation_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valisate Tokens Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\21629\\Desktop\\Danger!\\Projects\\GenAI\\data\\tmp_recipe_finetune_validation.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 73, 276\n",
      "mean / median: 145.0, 139.5\n",
      "p5 / p95: 102.0, 202.0\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 10, 69\n",
      "mean / median: 31.39, 29.0\n",
      "p5 / p95: 17.0, 50.0\n",
      "**************************************************\n",
      "Processing file: C:\\Users\\21629\\Desktop\\Danger!\\Projects\\GenAI\\data\\tmp_recipe_finetune_training.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 69, 227\n",
      "mean / median: 134.16831683168317, 130.0\n",
      "p5 / p95: 97.0, 180.0\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 8, 58\n",
      "mean / median: 28.15841584158416, 26.0\n",
      "p5 / p95: 16.0, 43.0\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Validate token counts\n",
    "\n",
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\") # default encoding used by gpt-4, turbo, and text-embedding-ada-002 models\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "files = [\n",
    "    r'C:\\Users\\21629\\Desktop\\Danger!\\Projects\\GenAI\\data\\tmp_recipe_finetune_validation.jsonl',\n",
    "    r'C:\\Users\\21629\\Desktop\\Danger!\\Projects\\GenAI\\data\\tmp_recipe_finetune_training.jsonl'\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    total_tokens = []\n",
    "    assistant_tokens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex.get(\"messages\", {})\n",
    "        total_tokens.append(num_tokens_from_messages(messages))\n",
    "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
    "    print('*' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-fed928cf29fa4f838aefe795e75d343f\n",
      "Validation file ID: file-cad549fe17b14f358326f192f7bbb355\n"
     ]
    }
   ],
   "source": [
    "# Upload fine-tuning files\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = openai.api_base,\n",
    "  api_key = openai.api_key ,\n",
    "  api_version = \"2024-05-01-preview\"  # This API version or later is required to access seed/events/checkpoint features\n",
    ")\n",
    "\n",
    "training_file_name = r'C:\\Users\\21629\\Desktop\\Danger!\\Projects\\GenAI\\data\\tmp_recipe_finetune_validation.jsonl'\n",
    "validation_file_name = r'C:\\Users\\21629\\Desktop\\Danger!\\Projects\\GenAI\\data\\tmp_recipe_finetune_training.jsonl'\n",
    "\n",
    "\n",
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "\n",
    "training_response = client.files.create(\n",
    "    file = open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "validation_response = client.files.create(\n",
    "    file = open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation file status: pending\n",
      "Training file status: pending\n"
     ]
    }
   ],
   "source": [
    "# List all files\n",
    "#check files status (needs to be Processed)\n",
    "response = client.files.list()\n",
    "\n",
    "# Iterate through the response to check the status of each file\n",
    "for file in response:\n",
    "    if file.id == training_file_id:\n",
    "        print(f\"Training file status: {file.status}\")\n",
    "    elif file.id == validation_file_id:\n",
    "        print(f\"Validation file status: {file.status}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit fine-tuning training job\n",
    "\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file = training_file_id,\n",
    "    validation_file = validation_file_id,\n",
    "    model = \"gpt-35-turbo-0613\"# Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters.\n",
    "   \n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List fine-tuning events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "     \"data\": [\n",
      "          {\n",
      "               \"id\": \"ftevent-049fcf2fe0f442ff880be400352c996c\",\n",
      "               \"created_at\": 1724014084,\n",
      "               \"level\": \"info\",\n",
      "               \"message\": \"Training tokens billed: 43000\",\n",
      "               \"object\": \"fine_tuning.job.event\",\n",
      "               \"type\": \"message\"\n",
      "          },\n",
      "          {\n",
      "               \"id\": \"ftevent-3507a0e50fa5413782470c76e15e0997\",\n",
      "               \"created_at\": 1724014084,\n",
      "               \"level\": \"info\",\n",
      "               \"message\": \"Completed results file: file-fc6f0466313646dda1d0ea6e5ded0c14\",\n",
      "               \"object\": \"fine_tuning.job.event\",\n",
      "               \"type\": \"message\"\n",
      "          },\n",
      "          {\n",
      "               \"id\": \"ftevent-b8db4a9cb551469da2b1f57d12c243d2\",\n",
      "               \"created_at\": 1724014080,\n",
      "               \"level\": \"info\",\n",
      "               \"message\": \"Postprocessing started.\",\n",
      "               \"object\": \"fine_tuning.job.event\",\n",
      "               \"type\": \"message\"\n",
      "          },\n",
      "          {\n",
      "               \"id\": \"ftevent-142afff0b27f4c30a4330ffabed5ea8e\",\n",
      "               \"created_at\": 1724014060,\n",
      "               \"level\": \"info\",\n",
      "               \"message\": \"Job succeeded.\",\n",
      "               \"object\": \"fine_tuning.job.event\",\n",
      "               \"type\": \"message\"\n",
      "          },\n",
      "          {\n",
      "               \"id\": \"ftevent-008dcbfc524679b008dcbfc524679b00\",\n",
      "               \"created_at\": 1724013262,\n",
      "               \"level\": \"info\",\n",
      "               \"message\": \"Step 300: training loss=0.20642662048339844\",\n",
      "               \"object\": \"fine_tuning.job.event\",\n",
      "               \"type\": \"metrics\",\n",
      "               \"data\": {\n",
      "                    \"step\": 300,\n",
      "                    \"train_loss\": 0.20642662048339844,\n",
      "                    \"train_mean_token_accuracy\": 0.9166666865348816,\n",
      "                    \"valid_loss\": 0.26103860360604747,\n",
      "                    \"valid_mean_token_accuracy\": 0.9629629629629629,\n",
      "                    \"full_valid_loss\": 0.146247292692068,\n",
      "                    \"full_valid_mean_token_accuracy\": 0.9704530531845043\n",
      "               }\n",
      "          },\n",
      "          {\n",
      "               \"id\": \"ftevent-008dcbfc51e71ba008dcbfc51e71ba00\",\n",
      "               \"created_at\": 1724013252,\n",
      "               \"level\": \"info\",\n",
      "               \"message\": \"Step 290: training loss=4.927317422698252E-05\",\n",
      "               \"object\": \"fine_tuning.job.event\",\n",
      "               \"type\": \"metrics\",\n",
      "               \"data\": {\n",
      "                    \"step\": 290,\n",
      "                    \"train_loss\": 0.00004927317422698252,\n",
      "                    \"train_mean_token_accuracy\": 1,\n",
      "                    \"valid_loss\": 0.09927387895255253,\n",
      "                    \"valid_mean_token_accuracy\": 0.9655172413793104\n",
      "               }\n",
      "          },\n",
      "          {\n",
      "               \"id\": \"ftevent-008dcbfc5187bd9008dcbfc5187bd900\",\n",
      "               \"created_at\": 1724013242,\n",
      "               \"level\": \"info\",\n",
      "               \"message\": \"Step 280: training loss=0.01328791119158268\",\n",
      "               \"object\": \"fine_tuning.job.event\",\n",
      "               \"type\": \"metrics\",\n",
      "               \"data\": {\n",
      "                    \"step\": 280,\n",
      "                    \"train_loss\": 0.01328791119158268,\n",
      "                    \"train_mean_token_accuracy\": 1,\n",
      "                    \"valid_loss\": 0.000051148083745216835,\n",
      "                    \"valid_mean_token_accuracy\": 1\n",
      "               }\n",
      "          },\n",
      "          {\n",
      "               \"id\": \"ftevent-008dcbfc51285f8008dcbfc51285f800\",\n",
      "               \"created_at\": 1724013232,\n",
      "               \"level\": \"info\",\n",
      "               \"message\": \"Step 270: training loss=0.0019427118822932243\",\n",
      "               \"object\": \"fine_tuning.job.event\",\n",
      "               \"type\": \"metrics\",\n",
      "               \"data\": {\n",
      "                    \"step\": 270,\n",
      "                    \"train_loss\": 0.0019427118822932243,\n",
      "                    \"train_mean_token_accuracy\": 1,\n",
      "                    \"valid_loss\": 0.38402086893717446,\n",
      "                    \"valid_mean_token_accuracy\": 0.8666666666666667\n",
      "               }\n",
      "          },\n",
      "          {\n",
      "               \"id\": \"ftevent-008dcbfc50c9017008dcbfc50c901700\",\n",
      "               \"created_at\": 1724013222,\n",
      "               \"level\": \"info\",\n",
      "               \"message\": \"Step 260: training loss=8.942740532802418E-05\",\n",
      "               \"object\": \"fine_tuning.job.event\",\n",
      "               \"type\": \"metrics\",\n",
      "               \"data\": {\n",
      "                    \"step\": 260,\n",
      "                    \"train_loss\": 0.00008942740532802418,\n",
      "                    \"train_mean_token_accuracy\": 1,\n",
      "                    \"valid_loss\": 0.12409337361653645,\n",
      "                    \"valid_mean_token_accuracy\": 0.9523809523809523\n",
      "               }\n",
      "          },\n",
      "          {\n",
      "               \"id\": \"ftevent-008dcbfc5069a36008dcbfc5069a3600\",\n",
      "               \"created_at\": 1724013212,\n",
      "               \"level\": \"info\",\n",
      "               \"message\": \"Step 250: training loss=0.15616241097450256\",\n",
      "               \"object\": \"fine_tuning.job.event\",\n",
      "               \"type\": \"metrics\",\n",
      "               \"data\": {\n",
      "                    \"step\": 250,\n",
      "                    \"train_loss\": 0.15616241097450256,\n",
      "                    \"train_mean_token_accuracy\": 0.9736841917037964,\n",
      "                    \"valid_loss\": 0.08001230118122507,\n",
      "                    \"valid_mean_token_accuracy\": 0.9787234042553191\n",
      "               }\n",
      "          }\n",
      "     ],\n",
      "     \"has_more\": true,\n",
      "     \"object\": \"list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10)\n",
    "print(response.model_dump_json(indent=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final training run results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(response.model_dump_json(indent=2))\n",
    "fine_tuned_model = response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy fine-tuned model\n",
    "\n",
    "import json\n",
    "import requests\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"token\")\n",
    "print(token)\n",
    "subscription = os.getenv(\"subscription\")\n",
    "print(subscription)\n",
    "resource_group = os.getenv(\"resource_group\")\n",
    "resource_name = os.getenv(\"resource_name\")\n",
    "model_deployment_name = os.getenv(\"model_deployment_name\")\n",
    "\n",
    "deploy_params = {'api-version': \"2024-05-01-preview\"}\n",
    "deploy_headers = {'Authorization': 'Bearer {}'.format(token), 'Content-Type': 'application/json'}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 1},\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": \"gpt-35-turbo-0613.ft-3bf62ca6cb934fa299f25b03b9ead914\", #retrieve this value from the previous call, it will look like gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "request_url = f'https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}'\n",
    "\n",
    "print('Creating a new deployment...')\n",
    "\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"powdered sugar\", \"butter\", \"peanut butter\", \"paraffin\", \"chocolate chips\"]\n"
     ]
    }
   ],
   "source": [
    "# Use the deployed customized model\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"OPENAI_API_BASE_fine_tuning\"),\n",
    "  api_key = os.getenv(\"OPENAI_API_KEY_fine_tuning\"),\n",
    "  api_version = \"2024-05-01-preview\",\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"deployment-finetuning\", # model = \"Custom deployment name you chose for your fine-tuning model\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.\"}, {\"role\": \"user\", \"content\": \"Title: couscous\\n\\nIngredients: [\\\"1 box powdered sugar\\\", \\\"8 oz. soft butter\\\", \\\"1 (8 oz.) peanut butter\\\", \\\"paraffin\\\", \\\"12 oz. chocolate chips\\\"]\\n\\nGeneric ingredients: \"}, {\"role\": \"assistant\", \"content\": \"[\\\"powdered sugar\\\", \\\"butter\\\", \\\"peanut butter\\\", \\\"paraffin\\\", \\\"chocolate chips\\\"]\"}\n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
